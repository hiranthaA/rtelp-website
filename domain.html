<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="description" content="">
    <meta name="author" content="">
    <title>Domain | RTELP</title>
    <link href="css/bootstrap.min.css" rel="stylesheet">
    <link href="css/font-awesome.min.css" rel="stylesheet">
    <link href="css/prettyPhoto.css" rel="stylesheet">
	<link href="css/item_hover.css" rel="stylesheet">
    <link href="css/animate.min.css" rel="stylesheet">
    <link href="css/main.css" rel="stylesheet">
    <link href="fonts/stylesheet.css" rel="stylesheet">
    <link href="css/responsive.css" rel="stylesheet">
    <!--[if lt IE 9]>
    <script src="js/html5shiv.js"></script>
    <script src="js/respond.min.js"></script>
    <![endif]-->       
    <link rel="shortcut icon" href="images/ico/favicon.ico">
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="images/ico/apple-touch-icon-144-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="114x114" href="images/ico/apple-touch-icon-114-precomposed.png">
    <link rel="apple-touch-icon-precomposed" sizes="72x72" href="images/ico/apple-touch-icon-72-precomposed.png">
    <link rel="apple-touch-icon-precomposed" href="images/ico/apple-touch-icon-57-precomposed.png">
</head><!--/head-->
<body>
    <header id="header">
        

        <nav class="navbar navbar-inverse" role="banner">
            <div class="container">
                <div class="navbar-header">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="index.html"><img img style="height:80px;vertical-align:initial" src="images/rtelp_logo.png" alt="logo"></a>
                </div>
                
                <div class="collapse navbar-collapse navbar-right">
                    <ul class="nav navbar-nav">
                        <li ><a href="index.html">Home</a></li>
						<li class="active"><a href="domain.html">Domain</a></li>
						<li><a href="milestone.html">Milestones</a></li>
						<li><a href="documents.html">Documents</a></li>
						<li><a href="presentations.html">Presentations</a></li>
                        <li><a href="about-us.html">About Us</a></li>
                        
                        <li><a href="contact-us.html">Contact</a></li>                        
                    </ul>
                </div>
            </div><!--/.container-->
        </nav><!--/nav-->
        
    </header><!--/header-->
    
    <section id="content" class="shortcode-item" style="min-height: calc(100vh - 189px);">
        <div class="container">
            <div class="row">
                
                    
                    <div class="tab-wrap">
                        <div class="media">
                            <div class="parrent pull-left">
                                <ul class="nav nav-tabs nav-stacked">
                                    
									<li class="active"><a href="#tab1" data-toggle="tab" class="analistic-02">Literatury Survey</a></li>
                                    <li class=""><a href="#tab2" data-toggle="tab" class="analistic-02">Research Gap</a></li>
									<li class=""><a href="#tab3" data-toggle="tab" class="tehnical">Research Problem</a></li>
                                    <li class=""><a href="#tab4" data-toggle="tab" class="tehnical">Objectives</a></li>
									<li class=""><a href="#tab5" data-toggle="tab" class="tehnical">Methodology</a></li>
									<li class=""><a href="#tab6" data-toggle="tab" class="tehnical">Technologies Used</a></li>
                                    
                                    
                                </ul>
                            </div>

                            <div class="parrent media-body" style="width:75%">
                                <div class="tab-content"  >
                                    
									<div class="tab-pane active in" id="tab1">
                                        <p align="justify">Virtual education is an emerging concept around the world. Students are starting to adapt to learn more productively through internet than traditional classroom due to many reasons. One of the main reasons is that every student has a different pace of catching-up with the teaching where some of them can be considered as fast learners while others may be slow. In traditional classroom scenarios, there is no solution to this fact. Another reason is the schedule flexibility. Through virtual learning, students can access their courses at any time anywhere with internet giving students the full control of their schedule of the day. Supporting the facts, universities provide students with the access to course materials via internet. Going beyond this, Real-time e-Learning Platform is a solution for the shortcomings in conventional education system mainly with universities.
											This proposed system is a web-based application where students can watch live lectures and interact with the lecturer and also playback previous lectures online. A tracking camera will be tracking the lecturer movements while recording and both lecturer’s video feed and the lecturer’s computer screen feed will be streamed. Also this system contains features to interact with the lecture. Student can ask questions from the lecturer remotely via his or her webcam in real-time and also can use a virtual whiteboard that is provided with the system to describe any misunderstandings.

                                     </div>

                                     <div  class="tab-pane " id="tab2">
                                        <p align="justify">When we consider about existing competitors of this field, the latency of the live streams is high where we cannot categorize their live streams as real-time. Main fact which has been affected to those is maintaining the quality of the live streams while delivering in real-time. Also supporting live streams for almost all the devices including mobile devices and different browsers is another focus of this research. 
											Compared to existing competitors of this field, most of them uses a fixed camera/cameras to take the feed of the lecturer moving in the lecture hall. If it’s one camera, then lecturer may not be visible in some parts of the lecture hall based on the positioning of the camera. To address that issue, cameras with wide view is used to covers the entire lecture hall. Then the students can’t see the lecturer properly. In a multi camera setups, some program is used to switch camera feeds according to the lecturer position. That will cost more money. Both these approaches have major impact on the student experience on using an e-learning platform.
											</p>
                                     </div>
									 
									  <div class="tab-pane" id="tab3">
                                        <p align="justify">The most common teaching and learning practice adopted by many enterprises has always been a classroom with one or more instructors and learners meeting physically and in real-time. But in this teaching model, there are several drawbacks which will be addressed as problems within this research.
											A classroom based learning experience means the class schedule is predetermined and not subject to change. Students must shape their personal schedules around school instead of the other way around. If plans unexpectedly change or an emergency comes up, the student cannot adjust the class schedule to turn in the work at a different time. This is one of the main problems that this research will find solutions for.
											 Content non-reusability is another problem that can be found in classroom learning. Memorizing or writing all the necessary content while listening to a lecture is difficult. Therefore, students might miss many important points that the lecturer is pointing out during a lecture.
											</p>
                                     </div>

                                     <div class="tab-pane" id="tab4">
                                        <p align="justify"> 
											<h2>Main Objective</h2>
											<p align="justify">Implementation of an e-Learning platform which facilitate real-time interactions
											between students and lecturers through a web application and also provide vital and
											useful statistics for the institute to improve their standards related to prevailing
											educational structure.<br><br>
											</p>

											<h2>Specific Objectives</h2>
											<h4>Live Streaming</h4>
											<p align="justify">1.	Minimize Latency
												Delivering a stream in real-time is a challenging task due to several factors. Main obstacle is the source of the stream should have a high bandwidth internet connection to broadcast the streams. Also the client should have a high bandwidth to view the stream without any delay. Main objective of this component would be finding solutions to address these issues.
												<br><br>
												2.	Multiple Device / Browser Support
												Students should be able to access the application from any of their devices and watch the streams. Also lecturers should be able to stream from their devices remotely. Therefore, the application should support most of the common devices and browsers.
												<br><br>
												3.	Record Live Streams
												Live streams have to be recorded and stored in order to facilitate students with lecture playback feature. This process should be very light weight and less CPU consuming task.
												</p>
											<br>
											<h4>Student Questioning and Whiteboard</h4>
											<p align="justify">
												The main objective of the this component is to build up a way to handle the real time questioning facility with the ongoing lecture. Student can mainly ask questions using his webcam and microphone through video and audio medias. Students can use chat box to interact with lecturer with text and uploading files when necessary. 
												The developed system is a web based application and SQHW component is focused with two main functions. <br>
												<br>1. Controlling the questioning function
												<br>2. Whiteboard function <br>
											</p>
											<br>
											<h4>Offline Playback</h4>
												<p align="justify">													
													1.	Minimize buffering pauses in playback
													A main objective of the player is to have minimum buffering pauses if not nil. The player should automatically change the source to match the source bitrate with the current network bandwidth.
													<br><br>
													2.	Keep the video and data feeds in-sync
													Video inputs for the player are independent feeds. The player should keep the feeds in-sync all the time to deliver the best user experience. Data feeds recorded from the whiteboard and chat window during the live lecture session should also played in sync with the videos.  
													<br><br>
													3.	Data collection and analysis
													User interactions with player should be captured relative to the position of the lecture playback. With these data, a detailed report has to be generated for each student, each lecture and each module.  

												</p>
											<br>
											<h4>Lecturer Tracking</h4>
												<p align="justify">
													1.	Real-time lecturer tracking
														Lecturer must be detected and tracked accurately in real time to generate camera control commands. Algorithm should perform efficiently even in low light environments. False detections must be reduced to improve the accuracy of the algorithm
													<br><br>
														2.	Handling multiple person detections (Person Re-Identification)
														If lecturer take a student to the stage or if someone passes across the lecture hall, multiple detections will be there. Since the camera only moves according to the lecturer, algorithm must be able to quickly differentiate between lecturer and the other detections and generate commands bases on that detections throughout the session
													<br><br>
														3.	Camera movements control
														Based on the detections, a PTZ camera has to be moved smoothly and accurately keeping lecturer in the center of the video output. If the detection is failed at some point, camera control module should have a predefined way to find the lecturer again.

												</p>

										</p>
										
									 </div>
                                     
                                    <div class="tab-pane" id="tab5">
                                        <p align="justify">
											<p align="justify">In order to develop this real-time application which is usable from multiple devices as laptops, tablets and smartphones we have chosen WebRTC technology. 
												WebRTC is an open source project developed by google to make web browsers support peer-to-peer 
												communications. On top of that, to implement our solution, we used Janus as the media server. 
												Janus is a general purpose WebRTC server which is capable of implementing WebRTC media 
												communications with browsers. Backend application server is developed with Node.JS while frontend 
												application is implemented using React.JS. </p>
											<br>
												<h4>Live Streaming</h4>
											<p align="justify">Main purpose of the live stream component is to transport video feeds from lecture's pc to 
													student’s pc with minimum latency and support multiple streaming sessions at once. 
													Once the lecturer starts to stream, system creates a new streaming session and streams related 
													to that session is broadcasted within the session. Once a peer joins to a specific session, 
													they will receive the related streams. Lecturer’s computer screen and a third-person perspective 
													camera view of the lecturer are the two video feeds that will be broadcasted within a session. 
													A feed from the lecturer’s mic is also streamed to the session. Those video feeds are encoded with h.264 codec 
													and audio feed is encoded with opus codec and send to the media server using RTP protocol.
													Once media server receives the streams, they are transcoded and broadcasted via WebRTC.</p>
											<p align="justify">For the purpose of playing back live streams, all the feeds are recorded and stored in the server as a custom file format mjr. 
													A separate file will be created for each audio and video stream which contains structured raw RTP packets exactly 
													as they are received by the server. This operation allows the server to perform recording 
													process as very less CPU intensive operation.</p>
											<p align="justify">After a steam is completed, media frames from the recorded RTP packets are extracted and saved to a media container 
													in a way that media applications can consume them. 
													Here video recordings are converted into .mp4 file format and audio feed as converted into .opus file format.</p>
												<br>
											<h4>Offline Playback</h4>
											<p align="justify">Main purpose of the lecture playback component is to provide a complete and uninterrupted playback experience of a past 
													lecture session. Additionally, students, lecturers and management should be able to view a 
													comprehensive analysis of the usage data from the player.</p>		
											<p align="justify">In order to be played in a video player with ability to seek, input videos should possess all the 
													necessary key frames. During the streaming process some key frames might not get created in the recorded stream. 
													Therefore, the post processed video streams are passed through another process to recreate key frames at regular intervals. </p>	
											<p align="justify">The playback player is developed to support adaptive bitrate streaming. 
													User of the playback player can explicitly select the video quality in which user wants the videos to be played.  
													In order to cater this requirement, the key frame recreated video streams are automatically converted into 3 different 
													video qualities with different resolutions and different bitrates. (1080p, 720p, 360p). After the conversion, each converted video 
													and the original audio will be spitted into 2 second segments which are indexed in order. These segments are 
													then fed into the player for the playback. If the user opted for automatic video quality, the player will select the 
													suitable video stream according to the current network bandwidth of the user.</p>	
											<p align="justify">In the player, two videos are played in sync along with the audio. 
													Chat data and whiteboard data related to the playing lecture session will be retrieved from the server 
													and displayed at the relevant timestamp giving the original experience of the live play. User can annotate 
													different sections of the video for future references.
													Player will keep track of the sections which are played by the user and get sent to the server. These data c
													ombined with the user information and lecture session information, will be used generate statistics. With these statistics, 
													lecturers can have a true feedback on each lecture session they conducted. Management can have an assessment on the lecture sessions 
													based on the students’ interactions with the videos. Students can have a self-evaluation based on own interactions with 
													each lecture session.</p>
													<br>
											<h4>Lecture Tracking</h4>	
											<p align="justify">There are mainly two feeds which is sent to streaming in this application. One is the lecture hall video which mainly 
													containing lecturer movements and the lecturer’s pc video with white board and chat in it. 
													This component is responsible for acquiring lecture hall video. In traditional video conferencing 
													and streaming, video of a moving person is acquired using a human cameraman or a fixed camera. Instead of that 
													PTZ (Pan Tilt Zoom) Camera is used to acquire the video. Camera movements are controlled by an advanced algorithm
													which keeps track of the lecturer and trying to keep him in the center of every fame. Algorithm is developed using 
													python by utilizing the power of modern deep learning. Person detection model (YOLO v3) is used to track the lecturer 
													and extract his location is the frame in real time. Then those coordinates are sent to a PID controller program 
													which will analyze the original center location of the frame and the lecturer’s position relative to it. 
													Then it will calculate the required amount of correction and the direction of the correction to keep lecturer centered in the frame.</p>
											<p align="justify">On site image processing server is used to process the video stream to minimize 
												the delay. Server will return set of VISCA commands to the PTZ Camera.
												 Uninterrupted second stream will be sent to the streaming server.</p>	
											<p align="justify">Siamese neural network will be used to computed a similarity score of two or more person 
												detections in the same frame. Based on the similarity score algorithm will keep tracking 
												the same person it tracked before. Both Siamese network and Yolo3 will be running on GPU to 
												maximize the performance (FPS).</p>
												<br>
												<h4>Student Questioning with Whiteboard</h4>
											<p align="justify">Main purpose of this component is to create live interaction with the lecturer and
													the student.</p>		
											<p align="justify">Whiteboard was implemented using vectors. So only the line coordinates will be
													transferred among users and created a vector based whiteboard. When a line
													draws, the coordinates of that drawing goes to the server. Then through the server
													socket connection that line coordinates are streaming to the all users of the current
													session. As this whiteboard is a light weight board run with vectors, small process
													will be used not like video based whiteboards. And also lecturer and the student
													both can use and draw with this whiteboard as a real time whiteboard. </p>	
											<p align="justify">The chat module is implemented to allow chat with each other with in the same session. Whether students can ask questions from the lecturer using
													chat or chat among other users is allowed. Users also can share images or pdf
													documents among others using the chat window.</p>	
											<p align="justify">There is a specific feature that allows lecturer to create polls. So
													the poll will be displayed to students and they will be able to pick the preferred
													answer. After the vote is done results will be analysis in the server according to
													the poll id and lecturer will able to see the results in a graphical way. For the graph
													drawings plotlyJS is used as a library. Finally, the vote graph can be shared among
													students. So the students also able to see the results in graphical way.</p>
											<p align="justify">Both whiteboard and the chat with live poll implemented using socket connection.
													For publishers and listeners one socket is created each and will be adding the
													necessary properties for the socket in server. Drawings in the whiteboard streams with minimum or no delay. Mostly it depends
													with the internet connection, because socket has no or very low latency.
													All these drawings and chats will be saved in a database for the usage of offline
													playback.</p>	
													<br>
										</p>

                                     </div>

                                     <div class="tab-pane" id="tab6">
                                        <p>
										<img src="images/node-js.png" width="200px">
										<img src="images/mysql.svg" width="200px">
										<img src="images/React-logo.png" width="200px">
										<img src="images/webrtc-logo.png" width="100px">
										<img src="images/python-logo.jpg" width="120px" >
										<img src="images/scikit-learn-logo.png" width="150px" >
										<img src="images/pycharm_logo.gif" width="150px">
										<img src="images/nvidia.png" width="200px" >
										<img src="images/Pytorch_logo.png" width="150px" >
										<img src="images/tf.png" width="150px" >
									
									</p>
                                     </div>
                                </div> <!--/.tab-content-->  
                            </div> <!--/.media-body--> 
                        </div> <!--/.media-->     
                    </div><!--/.tab-wrap-->               
                

                
            </div><!--/.row-->
        </div><!--/.container-->
    </section><!--/#content-->

	<style type="text/css">
	a{
	color:#4e4e4e;
	}
	</style>


    

 

    <footer id="footer" class="midnight-blue">
        <div class="container">
            <div class="row">
				<div class="col-sm-3"></div>
				<div class="col-sm-6" style="text-align: center;">
					Copyright © 2019 - RTELP. All Rights Reserved
				</div>
				<div class="col-sm-3"></div>
            </div>
        </div>
    </footer><!--/#footer-->

    <script src="js/jquery.js"></script>
    <script src="js/bootstrap.min.js"></script>
    <script src="js/jquery.prettyPhoto.js"></script>
    <script src="js/jquery.isotope.min.js"></script>
    <script src="js/main.js"></script>
    <script src="js/wow.min.js"></script>
</body>
</html>